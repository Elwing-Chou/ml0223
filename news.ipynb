{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "news.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1JmG6yTsBmvdln6WlBluZzo1jZvsViDEq",
      "authorship_tag": "ABX9TyMxVQu3Or0GCFVMTlpSksp7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elwing-Chou/ml0223/blob/main/news.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIongvSz0c6C"
      },
      "source": [
        "from zipfile import ZipFile\r\n",
        "f = ZipFile(\"/content/drive/MyDrive/news/chinese_news_trans.zip\")\r\n",
        "f.extractall()\r\n",
        "f = ZipFile(\"/content/drive/MyDrive/news/chinese_news_test.zip\")\r\n",
        "f.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd-VQSTF4Ogd"
      },
      "source": [
        "import os\r\n",
        "import glob\r\n",
        "import pandas as pd\r\n",
        "def process(base):\r\n",
        "    datas = {\r\n",
        "        \"content\":[],\r\n",
        "        \"ans\":[]\r\n",
        "    }\r\n",
        "    dirs = glob.glob(os.path.join(base, \"*\"))\r\n",
        "    for d in dirs:\r\n",
        "        fns1 = os.path.join(d, \"*.txt\")\r\n",
        "        fns2 = os.path.join(d, \"*.TXT\")\r\n",
        "        fns = glob.glob(fns1) + glob.glob(fns2)\r\n",
        "        for fn in fns:\r\n",
        "            with open(fn, \"r\", encoding=\"utf-8\") as f:\r\n",
        "                datas[\"content\"].append(f.read())\r\n",
        "            datas[\"ans\"].append(os.path.split(d)[-1])\r\n",
        "    df = pd.DataFrame(datas)\r\n",
        "    return df\r\n",
        "train_df = process(\"chinese_news_trans\")\r\n",
        "test_df = process(\"chinese_news_test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlnuhvYQGueA"
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEBTU3jJG5dA"
      },
      "source": [
        "# Series.replace({\"原本\":\"改成\"})\r\n",
        "# Series.unique/value_counts\r\n",
        "u = train_df[\"ans\"].unique()\r\n",
        "name2cat = {name:i for i, name in enumerate(u)}\r\n",
        "cat2name = {i:name for i, name in enumerate(u)}\r\n",
        "y_train = train_df[\"ans\"].replace(name2cat)\r\n",
        "y_test = test_df[\"ans\"].replace(name2cat)\r\n",
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvaxfT0-HDjK"
      },
      "source": [
        "from urllib.request import urlretrieve\r\n",
        "url = \"https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big\"\r\n",
        "urlretrieve(url, \"dict.txt.big\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qurtoS10HcfW"
      },
      "source": [
        "# Series.apply(func)\r\n",
        "import jieba\r\n",
        "jieba.set_dictionary(\"dict.txt.big\")\r\n",
        "def newscut(p):\r\n",
        "    return \" \".join(jieba.cut(p))\r\n",
        "x_train = train_df[\"content\"].apply(newscut)\r\n",
        "x_test = test_df[\"content\"].apply(newscut)\r\n",
        "x_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt7pmWFiHzH-"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "vec = CountVectorizer()\r\n",
        "x_train_count = vec.fit_transform(x_train)\r\n",
        "x_test_count = vec.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGsPjvn1H4WU"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "clf = MultinomialNB(alpha=0.1)\r\n",
        "clf.fit(x_train_count, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQwnlxb8H7Mp"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss\r\n",
        "pre = clf.predict(x_test_count)\r\n",
        "print(accuracy_score(y_test, pre))\r\n",
        "prob = clf.predict_proba(x_test_count)\r\n",
        "print(log_loss(y_test, prob))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkb6ev2_Kk1h"
      },
      "source": [
        "u"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR-pVKatKj4r"
      },
      "source": [
        "p = input(\"write:\")\r\n",
        "test = vec.transform([newscut(p)])\r\n",
        "prob = clf.predict_proba(test)[0]\r\n",
        "for i in range(len(u)):\r\n",
        "    print(u[i], \"的機率:\", round(prob[i], 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YcW_A2iKf4Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}